{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MTH8408 : Méthodes d'optimisation et contrôle optimal\n",
    " ## Laboratoire 4: Optimisation sans contraintes et méthodes itératives\n",
    "Tangi Migot et Paul Raynaud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, Krylov, NLPModels, Printf, Logging, SolverCore, Test, ADNLPModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 0: Introduction aux NLSModels\n",
    "\n",
    "On a vu dans les lab précédents l'utilisation des NLPModels pour représenter un problème d'optimisation. Dans le cas de l'optimisation de moindre carrées non-linéaires, il existe un type spécifique: **NLSModel**.\n",
    "\n",
    "$\\min_x \\frac{1}{2} \\| F(x) \\|^2$\n",
    "\n",
    "Comme un NLPModel classique on peut faire appels aux fonctions: obj, grad, hprod ...\n",
    "\n",
    "Mais on peut aussi utiliser des fonctions relatives à $F$:\n",
    "https://juliasmoothoptimizers.github.io/NLPModels.jl/stable/#Nonlinear-Least-Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? NLPModels.residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'équivalent des ADNLPModel pour ce cas est la fonction: ADNLSModel.\n",
    "Lien vers le site: https://juliasmoothoptimizers.github.io/ADNLPModels.jl/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? ADNLPModels.ADNLSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant les ADNLSModels écrire un modèle dont la fonction résidue est donné par FH ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test problem:\n",
    "FH(x) = [x[2]+x[1].^2-11, x[1]+x[2].^2-7]\n",
    "x0H = [10., 20.]\n",
    "###########################\n",
    "#Utilise FH et x0H pour créer un ADNLSModel\n",
    "himmelblau_nls = \n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1: Gauss-Newton\n",
    "\n",
    "Dans cet exercice, on complète une implémentation de la méthode Gauss-Newton avec région de confiance (paramétrée par $\\Delta$) discutée en cours.\n",
    "\n",
    "Il faut compléter les morceaux:\n",
    "- utiliser les fonctions des NLSModels pour obtenir F et sa jacobienne (ici on utilise pas la jacobienne mais juste le produit jacobienne-vecteur).\n",
    "Parcourez la documentation de NLPModels pour déterminer la fonction adéquat, indice les fonctions pour les NLSModels indiquent des `nls` au lieu de `nlp` dans la documentation.\n",
    "- Utiliser la fonction `lsmr` du package `Krylov.jl` pour résoudre le système linéaire avec une contrainte de `radius`. Lisez la [documentation de `lsmr`](https://jso.dev/Krylov.jl/stable/solvers/ls/#LSMR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gauss_newton(nlp      :: AbstractNLSModel, \n",
    "                      x        :: AbstractVector, \n",
    "                      ϵ        :: AbstractFloat;\n",
    "                      η₁       :: AbstractFloat = 1e-3, \n",
    "                      η₂       :: AbstractFloat = 0.66, \n",
    "                      σ₁       :: AbstractFloat = 0.25, \n",
    "                      σ₂       :: AbstractFloat = 2.0,\n",
    "                      max_eval :: Int = 1_000, \n",
    "                      max_time :: AbstractFloat = 60.,\n",
    "                      max_iter :: Int = typemax(Int64)\n",
    "                      )\n",
    "    ######################################################\n",
    "    Fx = # le résidu\n",
    "    Jx = # operateur qui représente le jacobien du résidu\n",
    "    ######################################################\n",
    "    normFx = norm(Fx)\n",
    "\n",
    "    Δ = 1.\n",
    "\n",
    "    iter = 0    \n",
    "\n",
    "    el_time = 0.0\n",
    "    tired   = neval_residual(nlp) > max_eval || el_time > max_time\n",
    "    status  = :unknown\n",
    "\n",
    "    start_time = time()\n",
    "    too_small  = false\n",
    "    normdual   = norm(Jx' * Fx)\n",
    "    optimal    = min(normFx, normdual) ≤ ϵ\n",
    "\n",
    "    @info log_header([:iter, :nf, :primal, :status, :nd, :Δ],\n",
    "    [Int, Int, Float64, String, Float64, Float64],\n",
    "    hdr_override=Dict(:nf => \"#F\", :primal => \"‖F(x)‖\", :nd => \"‖d‖\"))\n",
    "\n",
    "    while !(optimal || tired || too_small)\n",
    "\n",
    "        #################################\n",
    "        #Compute a direction satisfying the trust-region constraint\n",
    "        (d, stats)  = \n",
    "        #################################\n",
    "      \n",
    "        too_small = norm(d) < 1e-15\n",
    "        if too_small #the direction is too small\n",
    "            status = :too_small\n",
    "        else\n",
    "            xp      = x + d\n",
    "            ###########################\n",
    "            Fxp     = # évalue le résidu en xp\n",
    "            ###########################\n",
    "            normFxp = norm(Fxp)\n",
    "\n",
    "            Pred = 0.5 * (normFx^2 - norm(Jx * d + Fx)^2)\n",
    "            Ared = 0.5 * (normFx^2 - normFxp^2)\n",
    "\n",
    "            if Ared/Pred < η₁\n",
    "                Δ = max(1e-8, Δ * σ₁)\n",
    "                status = :reduce_Δ\n",
    "            else #success\n",
    "                x  = xp\n",
    "                ###########################\n",
    "                Jx = # réevalue le jacobien en x\n",
    "                ###########################\n",
    "                Fx = Fxp\n",
    "                normFx = normFxp\n",
    "                status = :success\n",
    "                if Ared/Pred > η₂ && norm(d) >= 0.99 * Δ\n",
    "                    Δ *= σ₂\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        @info log_row(Any[iter, neval_residual(nlp), normFx, status, norm(d), Δ])\n",
    "\n",
    "        el_time      = time() - start_time\n",
    "        iter   += 1\n",
    "\n",
    "        many_evals   = neval_residual(nlp) > max_eval\n",
    "        iter_limit   = iter > max_iter\n",
    "        tired        = many_evals || el_time > max_time || iter_limit\n",
    "        normdual     = norm(Jx' * Fx)\n",
    "        optimal      = min(normFx, normdual) ≤ ϵ\n",
    "    end\n",
    "\n",
    "    status = if optimal \n",
    "        :first_order\n",
    "    elseif tired\n",
    "        if neval_residual(nlp) > max_eval\n",
    "            :max_eval\n",
    "        elseif el_time > max_time\n",
    "            :max_time\n",
    "        elseif iter > max_iter\n",
    "            :max_iter\n",
    "        else\n",
    "            :unknown_tired\n",
    "        end\n",
    "    elseif too_small\n",
    "        :stalled\n",
    "    else\n",
    "        :unknown\n",
    "    end\n",
    "\n",
    "    return GenericExecutionStats(nlp; status, solution = x,\n",
    "                                 objective = normFx^2 / 2,\n",
    "                                 dual_feas = normdual,\n",
    "                                 iter = iter, \n",
    "                                 elapsed_time = el_time)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = gauss_newton(himmelblau_nls, himmelblau_nls.meta.x0, 1e-6)\n",
    "@test stats.status == :first_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2: Méthode Levenberg-Marquard inexacte\n",
    "\n",
    "Dans cet exercice, on complète une implémentation de la méthode Levenberg-Marquardt. Pour compléter le code `lm_param` on va utiliser les fonctions suivantes:\n",
    "- `dsol` qui calcul la solution du système \n",
    "$\\min_x \\frac{1}{2}\\|J(x) d + F(x)\\| + \\lambda \\|x\\|^2$\n",
    "avec la fonction `lsqr` du package `Krylov.jl`.\n",
    "- `multi_sol` qui pour un entier nl donné et un $\\mu$ va résoudre le problème de dsol pour nl valeurs de $\\lambda$ (autour de la valeur $\\mu$). Par exemple, pour $\\mu=10^{-6}$ et $nl=3$, on prendra $\\lambda=10^{-7}, 10^{-6},10^{-5}$.\n",
    "Parmis les `nl` directions calculées, on retourne celle qui donne la plus petite valeur de $\\|F(x+d)\\|^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function dsol(Fx, Jx, λ, τ)\n",
    "    # TODO.\n",
    "    return d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function multi_sol(nlp, x, Fx, Jx, λ, τ; nl = 3)\n",
    "    # TODO\n",
    "    return d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lm_param(nlp      :: AbstractNLSModel, \n",
    "                  x        :: AbstractVector, \n",
    "                  ϵ        :: AbstractFloat;\n",
    "                  η₁       :: AbstractFloat = 1e-3, \n",
    "                  η₂       :: AbstractFloat = 0.66, \n",
    "                  σ₁       :: AbstractFloat = 10.0, \n",
    "                  σ₂       :: AbstractFloat = 0.5,\n",
    "                  max_eval :: Int = 10_000, \n",
    "                  max_time :: AbstractFloat = 60.,\n",
    "                  max_iter :: Int = typemax(Int64)\n",
    "                  )\n",
    "    ######################################################\n",
    "    Fx = # le résidu\n",
    "    Jx = # operateur qui représente le jacobien du résidu\n",
    "    ######################################################\n",
    "    normFx   = norm(Fx)\n",
    "    normdual = norm(Jx' * Fx)\n",
    "\n",
    "    iter = 0    \n",
    "    λ = 0.0\n",
    "    λ₀ = 1e-6\n",
    "    η = 0.5\n",
    "    τ = η * normdual\n",
    "\n",
    "    el_time = 0.0\n",
    "    tired   = neval_residual(nlp) > max_eval || el_time > max_time\n",
    "    status  = :unknown\n",
    "\n",
    "    start_time = time()\n",
    "    too_small  = false\n",
    "    optimal    = min(normFx, normdual) ≤ ϵ\n",
    "\n",
    "    @info log_header([:iter, :nf, :primal, :status, :nd, :λ],\n",
    "    [Int, Int, Float64, String, Float64, Float64],\n",
    "    hdr_override=Dict(:nf => \"#F\", :primal => \"‖F(x)‖\", :nd => \"‖d‖\"))\n",
    "\n",
    "    while !(optimal || tired || too_small)\n",
    "\n",
    "        ###########################\n",
    "        # (d, stats)  = lsqr(Jx, -Fx, λ = λ, atol = τ)\n",
    "        d = multi_sol(nlp, x, Fx, Jx, λ, τ)\n",
    "        ###########################\n",
    "        \n",
    "        too_small = norm(d) < 1e-16\n",
    "        if too_small #the direction is too small\n",
    "            status = :too_small\n",
    "        else\n",
    "            xp      = x + d\n",
    "            ###########################\n",
    "            Fxp     = # évalue le résidu en xp\n",
    "            ###########################\n",
    "            normFxp = norm(Fxp)\n",
    "\n",
    "            Pred = 0.5 * (normFx^2 - norm(Jx * d + Fx)^2 - λ*norm(d)^2)\n",
    "            Ared = 0.5 * (normFx^2 - normFxp^2)\n",
    "\n",
    "            if Ared/Pred < η₁\n",
    "                λ = max(λ₀, σ₁ * λ)\n",
    "                status = :increase_λ\n",
    "            else #success\n",
    "                x  = xp\n",
    "                ###########################\n",
    "                Jx = # réevalue le jacobien en x\n",
    "                ###########################\n",
    "                Fx = Fxp\n",
    "                normFx = normFxp\n",
    "                status = :success\n",
    "                if Ared/Pred > η₂\n",
    "                    λ = max(λ * σ₂, λ₀)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        @info log_row(Any[iter, neval_residual(nlp), normFx, status, norm(d), λ])\n",
    "\n",
    "        el_time      = time() - start_time\n",
    "        iter        += 1\n",
    "        many_evals   = neval_residual(nlp) > max_eval\n",
    "        iter_limit   = iter > max_iter\n",
    "        tired        = many_evals || el_time > max_time || iter_limit\n",
    "        normdual     = norm(Jx' * Fx)\n",
    "        optimal      = min(normFx, normdual) ≤ ϵ\n",
    "\n",
    "        η = λ == 0.0 ? min(0.5, 1/iter, normdual) : min(0.5, 1/iter)\n",
    "        τ = η * normdual\n",
    "    end\n",
    "\n",
    "    status = if optimal \n",
    "        :first_order\n",
    "    elseif tired\n",
    "        if neval_residual(nlp) > max_eval\n",
    "            :max_eval\n",
    "        elseif el_time > max_time\n",
    "            :max_time\n",
    "        elseif iter > max_iter\n",
    "            :max_iter\n",
    "        else\n",
    "            :unknown_tired\n",
    "        end\n",
    "    elseif too_small\n",
    "        :stalled\n",
    "    else\n",
    "        :unknown\n",
    "    end\n",
    "\n",
    "    return GenericExecutionStats(status, nlp, solution = x,\n",
    "                                 objective = normFx^2 / 2,\n",
    "                                 dual_feas = normdual,\n",
    "                                 iter = iter, \n",
    "                                 elapsed_time = el_time)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = lm_param(himmelblau_nls, himmelblau_nls.meta.x0, 1e-6)\n",
    "@test stats.status == :first_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3: Rocket Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les cellules ci-dessous nous introduisons un modèle de contrôle optimal (cf. https://en.wikipedia.org/wiki/Optimal_control ) pour le contrôle d'une fusée dont une version discrétisée a été modélisé avec JuMP:\n",
    "\n",
    "Le lien vers le tutoriel:\n",
    "https://nbviewer.jupyter.org/github/jump-dev/JuMPTutorials.jl/blob/master/notebook/modelling/rocket_control.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Ipopt\n",
    "\n",
    "# Create JuMP model, using Ipopt as the solver\n",
    "rocket = Model(optimizer_with_attributes(Ipopt.Optimizer, \"print_level\" => 0))\n",
    "\n",
    "# Constants\n",
    "# Note that all parameters in the model have been normalized\n",
    "# to be dimensionless. See the COPS3 paper for more info.\n",
    "h_0 = 1    # Initial height\n",
    "v_0 = 0    # Initial velocity\n",
    "m_0 = 1    # Initial mass\n",
    "g_0 = 1    # Gravity at the surface\n",
    "\n",
    "T_c = 3.5  # Used for thrust\n",
    "h_c = 500  # Used for drag\n",
    "v_c = 620  # Used for drag\n",
    "m_c = 0.6  # Fraction of initial mass left at end\n",
    "\n",
    "c     = 0.5 * sqrt(g_0 * h_0)  # Thrust-to-fuel mass\n",
    "m_f   = m_c * m_0            # Final mass\n",
    "D_c   = 0.5 * v_c * m_0 / g_0    # Drag scaling\n",
    "T_max = T_c * g_0 * m_0        # Maximum thrust\n",
    "\n",
    "n = 800   # Time steps\n",
    "\n",
    "@variables(rocket, begin\n",
    "    Δt ≥ 0, (start = 1/n) # Time step\n",
    "    # State variables\n",
    "    v[1:n] ≥ 0            # Velocity\n",
    "    h[1:n] ≥ h_0          # Height\n",
    "    m_f ≤ m[1:n] ≤ m_0    # Mass\n",
    "    # Control\n",
    "    0 ≤ T[1:n] ≤ T_max    # Thrust\n",
    "end)\n",
    "\n",
    "# Objective: maximize altitude at end of time of flight\n",
    "@objective(rocket, Max, h[n])\n",
    "\n",
    "# Initial conditions\n",
    "@constraints(rocket, begin\n",
    "    v[1] == v_0\n",
    "    h[1] == h_0\n",
    "    m[1] == m_0\n",
    "    m[n] == m_f\n",
    "end)\n",
    "\n",
    "# Forces\n",
    "# Drag(h,v) = Dc v^2 exp( -hc * (h - h0) / h0 )\n",
    "@NLexpression(rocket, drag[j = 1:n], D_c * (v[j]^2) * exp(-h_c * (h[j] - h_0) / h_0))\n",
    "# Grav(h)   = go * (h0 / h)^2\n",
    "@NLexpression(rocket, grav[j = 1:n], g_0 * (h_0 / h[j])^2)\n",
    "# Time of flight\n",
    "@NLexpression(rocket, t_f, Δt * n)\n",
    "\n",
    "# Dynamics\n",
    "for j in 2:n\n",
    "    # h' = v\n",
    "    \n",
    "    # Rectangular integration\n",
    "    # @NLconstraint(rocket, h[j] == h[j - 1] + Δt * v[j - 1])\n",
    "    \n",
    "    # Trapezoidal integration\n",
    "    @NLconstraint(rocket,\n",
    "        h[j] == h[j - 1] + 0.5 * Δt * (v[j] + v[j - 1]))\n",
    "\n",
    "    # v' = (T-D(h,v))/m - g(h)\n",
    "    \n",
    "    # Rectangular integration\n",
    "    # @NLconstraint(rocket, v[j] == v[j - 1] + Δt *(\n",
    "    #                 (T[j - 1] - drag[j - 1]) / m[j - 1] - grav[j - 1]))\n",
    "    \n",
    "    # Trapezoidal integration\n",
    "    @NLconstraint(rocket,\n",
    "        v[j] == v[j-1] + 0.5 * Δt * (\n",
    "            (T[j] - drag[j] - m[j] * grav[j]) / m[j] +\n",
    "            (T[j - 1] - drag[j - 1] - m[j - 1] * grav[j - 1]) / m[j - 1]))\n",
    "\n",
    "    # m' = -T/c\n",
    "\n",
    "    # Rectangular integration\n",
    "    # @NLconstraint(rocket, m[j] == m[j - 1] - Δt * T[j - 1] / c)\n",
    "    \n",
    "    # Trapezoidal integration\n",
    "    @NLconstraint(rocket,\n",
    "        m[j] == m[j - 1] - 0.5 * Δt * (T[j] + T[j-1]) / c)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for the control and state\n",
    "println(\"Solving...\")\n",
    "status = optimize!(rocket)\n",
    "\n",
    "# Display results\n",
    "# println(\"Solver status: \", status)\n",
    "println(\"Max height: \", objective_value(rocket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.(h)[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can visualize the state and control variables\n",
    "using Gadfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_plot = plot(x = (1:n) * value.(Δt), y = value.(h)[:], Geom.line,\n",
    "                Guide.xlabel(\"Time (s)\"), Guide.ylabel(\"Altitude\"))\n",
    "m_plot = plot(x = (1:n) * value.(Δt), y = value.(m)[:], Geom.line,\n",
    "                Guide.xlabel(\"Time (s)\"), Guide.ylabel(\"Mass\"))\n",
    "v_plot = plot(x = (1:n) * value.(Δt), y = value.(v)[:], Geom.line,\n",
    "                Guide.xlabel(\"Time (s)\"), Guide.ylabel(\"Velocity\"))\n",
    "T_plot = plot(x = (1:n) * value.(Δt), y = value.(T)[:], Geom.line,\n",
    "                Guide.xlabel(\"Time (s)\"), Guide.ylabel(\"Thrust\"))\n",
    "draw(SVG(6inch, 6inch), vstack(hstack(h_plot, m_plot), hstack(v_plot, T_plot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:     \n",
    "    - i) Transformer le modèle JuMP utilisé ci-dessus en un NLPModel en utilisant le package `NLPModelsJuMP`.    \n",
    "    - ii) Résoudre ce nouveau modèle avec `Ipopt` en utilisant `NLPModelsIpopt`.    \n",
    "    - iii) Calcul séparément la différence entre les h,v,m,T, Δt calculés.    \n",
    "    - iv) Est-ce que le contrôle T atteint ses bornes ?    \n",
    "    - v) Reproduire les graphiques ci-dessous avec la solution calculée via `NLPModelsIpopt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NLPModels, LinearAlgebra, NLPModelsJuMP, NLPModelsIpopt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
